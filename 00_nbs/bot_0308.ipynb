{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66567b4-19bc-4601-9335-f31dd39d2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b737cb-c381-4c24-992c-19f94132a55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev\n"
     ]
    }
   ],
   "source": [
    "from food.psql import *\n",
    "from mytools.tools import get_logger\n",
    "logger = get_logger(engine,'bot_logs','food')\n",
    "logger.debug({'msg':'starting bot'})\n",
    "from aiogram import Bot, Dispatcher, executor, types\n",
    "from aiogram.types import ContentType\n",
    "from aiogram.dispatcher.filters.state import State, StatesGroup\n",
    "from aiogram.types.message import ContentTypes\n",
    "from aiogram.dispatcher import FSMContext\n",
    "from aiogram.contrib.fsm_storage.memory import MemoryStorage\n",
    "from sqlalchemy import update\n",
    "from aiogram.dispatcher.filters.state import State, StatesGroup\n",
    "from aiogram.utils.callback_data import CallbackData\n",
    "import typing\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "\n",
    "from food.paths import *\n",
    "\n",
    "\n",
    "API_TOKEN = bot_token\n",
    "\n",
    "from food.paths import *\n",
    "#from food.search import *\n",
    "import pandas as  pd\n",
    "import pytz\n",
    "timezones = pytz.all_timezones\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "import urllib\n",
    "from tzwhere import tzwhere\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2abacf48-8f81-404e-ab1e-8a5e33b52d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentor.segment import get_segment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd78ec5-9a9a-4119-b592-9ae63346774e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/mytools/mytools/visual.py:26: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  series2tensor = lambda series:torch.tensor([np.array(c) for c in series.values])\n"
     ]
    }
   ],
   "source": [
    "from food.search import *\n",
    "from mytools.psql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9a2422-81a5-405f-b1f2-c401da4c4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7547fd2e-e5e9-40e2-8f0c-6454333003ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def  async_insert_on_conflict(*args, **qwargs):\n",
    "    return insert_on_conflict(*args, **qwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae1d9bb-7291-44f3-ad78-5c8dc1d50528",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def add_sender(message):\n",
    "    logger.debug({'func':'add_sender','id_key':'user_id','id_value':message['from']['id'],'msg':'add_sender'})\n",
    "    sender = message['from'].to_python()\n",
    "    sender = pd.DataFrame(sender,index=[0]).drop(columns =['is_bot'])\n",
    "    await async_insert_on_conflict(sender,'users',unique_cols=['id'],engine = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65badfc3-3f7e-4895-902e-3f84afcf8e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nutrition(masks):\n",
    "    attributes = ['energy','protein','carb','fat']\n",
    "    nutrition ={}\n",
    "    for m,a in zip(masks,attributes): nutrition[a] = float(m[m!=0].mean())\n",
    "    return pd.DataFrame(nutrition,index = ['']).fillna(0).astype(int).to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2607047b-76bf-4982-b3a2-7db9bf9df478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2file_obj(img):\n",
    "    o = io.BytesIO()\n",
    "    f = img.format if img.format else 'jpeg'\n",
    "    img.save(o, format=f)\n",
    "    return o.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a042e2d-0bb8-48ba-a448-99e1f871064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_image2file_obj(*args,**kwargs):\n",
    "    return image2file_obj(*args,**kwargs)\n",
    "\n",
    "async def async_search(*args,**kwargs):\n",
    "    return search(*args,**kwargs)\n",
    "\n",
    "async def async_visualize_array(*args,**kwargs):\n",
    "    return visualize_array(*args,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dc92a36-f705-4332-97aa-d800de2d076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/segmentator/mmseg/models/builder.py:59: UserWarning: train_cfg and test_cfg is deprecated, please specify them in model\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pre-trained weight from imagenet21k\n"
     ]
    }
   ],
   "source": [
    "model_path = checkpoints_path.ls()[0]\n",
    "segment_model = get_segment_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c1810d-777b-4f12-93f5-86a8d5cf4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = Bot(token=API_TOKEN)\n",
    "storage = MemoryStorage()\n",
    "dp = Dispatcher(bot, storage=storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc41be3-0d97-4a34-81d7-8843ae3fbe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes_table = Dishes.__table__\n",
    "\n",
    "add_dish_cb     = CallbackData('add to food log', 'action')\n",
    "remove_cb       = CallbackData('remove from food log', 'action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6734b0e-048d-4ae6-b020-b8f684f06f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_score(cals,values,scores):\n",
    "    arrays = []\n",
    "    for n in range(len(values)-1):\n",
    "        arrays.append(np.stack([np.linspace(values[n],values[n+1]),np.flip(np.linspace(scores[n+1],scores[n]))]))\n",
    "        formula = np.concatenate(arrays,axis=1)\n",
    "        c = formula[0][formula[0] <cals][-1]\n",
    "\n",
    "    return formula[1][formula[0]==c].astype(np.int32)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1becb44c-098b-4390-906c-8d699fd4b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_food_score(cals,protein):\n",
    "    return attribute_score(cals   ,calore_scores[0],calore_scores[1]),attribute_score(protein,protein_scores[0],protein_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45539968-0992-47aa-9808-5ac6de5e0aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_scores = ([0,10,20,35],\n",
    "                  [30,90,100,100])\n",
    "calore_scores  = ([0,  90, 100,150,200,300,400],\n",
    "                  [100,100, 95,70 ,60 ,50 ,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7152e46-d72f-4b89-ac25-4875d09c1461",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ':thumbs_down:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecdd4f52-ba66-429e-a63a-e492d0042530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#emoji.emojize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4d9e031-c746-43cc-9d85-7f11b54e59bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_keyboard(t, unit = None):\n",
    "    markup = types.InlineKeyboardMarkup()\n",
    "    if t == 'add to food log' :  \n",
    "        # btns_text = ['add to food log',':thumbs_up:',':thumbs_down:']\n",
    "        markup.add(types.InlineKeyboardButton('add to food log', callback_data=add_dish_cb.new(action='add_dish')))\n",
    "        # markup.add(*(types.InlineKeyboardButton('add to food log', callback_data=remove_cb.new(action=text)) for text in btns_text))\n",
    "         \n",
    "\n",
    "    elif t == 'remove from food log':\n",
    "\n",
    "        btns_text = ('remove from food log',)\n",
    "        markup.add(types.InlineKeyboardButton('remove from food log', callback_data=remove_cb.new(action='remove')))\n",
    "        \n",
    "        \n",
    "        # markup.add(*(types.InlineKeyboardButton(text, callback_data=remove_cb.new(action=text)) for text in btns_text))\n",
    "\n",
    "    return markup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04f95193-57d2-44e1-b333-8af5d894f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dp.message_handler(commands=['start'])\n",
    "async def start_command(message: types.Message):\n",
    "    global m \n",
    "    m = message\n",
    "    logger.debug({'func':'start_command','id_key':'user_id','id_value':message['from']['id'],'msg':'start_command'})\n",
    "    await add_sender(message)\n",
    "\n",
    "    await message.reply(\"\"\" Take <b>food pictures</b> to improve your diet.\\n \n",
    "\n",
    "No  more calorie counting, food weight measurement, manual food logging. <b>A single picture per dish is the only thing you need to do</b> .\\n\n",
    "Your photos are returned back to you colorised as a heat map. Just choose more of coloured in green  next time and less of colorer in  red.\\n\n",
    "Get your <b>nutrition score</b> updated with every meal, try to keep it high.\\n\n",
    "<b>Calorie density</b> is a scientific approach that allows to <b>eat till satisfaction while still cutting back on calories</b>. That idea is implemented <b>with the power of AI</b> to be as easy to follow as taking pictures.\\n\n",
    "\n",
    "\n",
    "<b>how it gain great results:</b>\\n\n",
    "- eat only till sutisfaction and do not overeat.\n",
    "- try not to drink your calories.\n",
    "- take photos of all the foods <b>from the same distance</b> and with the same focus distance each time\\n\n",
    "- <b>use flash</b>\\n\n",
    "\n",
    "Now <b>take a picture of your next dish</b> with the bot!\"\"\",parse_mode = 'HTML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c19d9955-e683-4445-9bf0-166d684b3bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take <b>pictures of your food</b> to know how healthy it is with the power of <b>AI</b>.\\n\\\n",
    "    \n",
    "#     Get your <b>nutrition score</b> updated every time you take a meal.\\n \\\n",
    "#     Keep high food score to stay fit and healthy.\\n<b>Take a picture of your next dish with the bot!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "220cad28-8e94-4dcb-8fb4-5621d52c8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dp.message_handler(content_types=ContentType.PHOTO,state='*')\n",
    "async def process_photo(message: types.Message, state: FSMContext):\n",
    "    logger.debug({'func':'process_photo','id_key':'user_id','id_value':message['from']['id'],'msg':'process_photo started'})\n",
    "    \n",
    "    processing_reply = await message.reply(\"\"\"\\xa0 your picture is being processed ...\"\"\",\n",
    "                           parse_mode = 'HTML')\n",
    "    \n",
    "    await types.ChatActions.upload_photo()\n",
    "    photo  = message['photo'][-1]\n",
    "    path = reference_images_path/photo['file_id']\n",
    "    await photo.download(path)\n",
    "    \n",
    "    # image_url    = await photo.get_url()\n",
    "    image_url      = f'https://dima.grankin.eu/reference_images/{photo[\"file_id\"]}'\n",
    "    \n",
    "    img,clip_df,masks,stats = await async_search(segment_model,path,prompt_factor=0.1,min_score=0.22,exand_times =2)\n",
    "    \n",
    "    print('after search')\n",
    "\n",
    "    dish = clip_df.reset_index()[['id','score','area']]\n",
    "    dish['photo_id']         = photo['file_id']\n",
    "    dish['photo_message_id'] = message['message_id']\n",
    "    sender = message['from'].to_python()\n",
    "    dish['user_id'] = sender['id']\n",
    "    dish['ml_version'] = 0.4 \n",
    "    dish['timestamp']=pd.Timestamp.utcnow()\n",
    "    dish = dish.rename(columns = {\"id\":'food_id'})\n",
    "    \n",
    "    output = '; '.join(clip_df['description'].tolist())\n",
    "\n",
    "    print('downloaded')\n",
    "\n",
    "    img_o = await async_image2file_obj(img)\n",
    "    \n",
    "    await processing_reply.delete()\n",
    "    reply = await message.reply_photo(img_o,caption=f'<i>per 100 gram</i>:\\n{plot_nutrition(masks)} \\n\\n{output}', reply_markup=get_keyboard('add to food log'),parse_mode = 'HTML')\n",
    "    dish['message_id'] = reply['message_id']\n",
    "    \n",
    "    dish.to_sql('dishes',con=engine,if_exists='append',index = False,schema = 'food')\n",
    "    \n",
    "    logger.debug({'func':'process_photo','id_key':'user_id','id_value':message['from']['id'],'msg':'process_photo finished'})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e58770c-f5a0-496f-83e1-1b2f18e3eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_today_consumed(user_id):\n",
    "\n",
    "    today_consumed = pd.read_sql( f\"\"\"select f.energy, f.protein, d.area,d.timestamp\n",
    "                           from food.foods f\n",
    "                           join food.dishes d on (f.id = d.food_id)\n",
    "                           where d.user_id = {user_id} and \n",
    "                                 d.timestamp > now() - interval '24 hours' and\n",
    "                                 d.added is true\"\"\" ,engine).set_index(\"timestamp\")\n",
    "\n",
    "    \n",
    "    area = today_consumed['area'].sum()\n",
    "    if area>0:\n",
    "        cals = np.average(today_consumed['energy'] ,weights=today_consumed['area'])\n",
    "        prts = np.average(today_consumed['protein'],weights=today_consumed['area'])\n",
    "        cals_score, prts_score =  get_food_score(cals,prts)\n",
    "        food_score = int((cals_score*2+prts_score)/3)\n",
    "\n",
    "\n",
    "        return int(food_score),int(cals),int(cals_score),int(prts_score),int(prts),area\n",
    "    \n",
    "    else: return None,None,None,None,None,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c406640-e6d1-4887-9c34-f57c6c74f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def add_remove(query,add):\n",
    "    \n",
    "    msg = query.to_python()['message']['caption']\n",
    "    msg = msg.split('\\xa0')[0] if '\\xa0' in msg else msg\n",
    "    \n",
    "    stmt = (\n",
    "        dishes_table.update()\n",
    "                    .where(dishes_table.c.message_id == query['message']['message_id'])\n",
    "                    .values(added=add)\n",
    "                    .returning(dishes_table.c.id)\n",
    "        )\n",
    "    session.execute(stmt)\n",
    "    session.commit()\n",
    "    \n",
    "    user_id = query['from']['id']\n",
    "    \n",
    "    food_score,cals,cals_score,prts,prts_score,area = await get_today_consumed(user_id)\n",
    "    \n",
    "    if cals_score < 70:\n",
    "        if prts_score <70:\n",
    "            m = 'Keep choosing foods in a <b>greener</b> spectrum and have a bit of <b>protein</b> rich foods'\n",
    "        else:\n",
    "            m = 'Keep choosing foods in a <b>greener</b> spectrum'\n",
    "    else:\n",
    "        if prts_score <70:\n",
    "            m = 'Your calories are good. Try to have more of <b>protein</b> rich foods to improve your nutrition score'\n",
    "        else:\n",
    "            m = 'you are doing <b>great</b>!'\n",
    "\n",
    "\n",
    "    \n",
    "    if add:\n",
    "        if area>300000: \n",
    "            msg = f\"{msg}\\n\\n\\xa0your <b>nutrition score</b> for the last 24 hours is <b>{food_score}</b>\"\n",
    "            msg = f\"{msg}\\n\\n\\xa0<i>{m}</i>\"\n",
    "        else:\n",
    "            msg = f\"{msg}\\n\\n\\xa0keep adding your dishes to get your food score\"\n",
    "            \n",
    "        \n",
    "    keyboard = 'remove from food log' if add else 'add to food log' \n",
    "\n",
    "    await bot.edit_message_caption(query.from_user.id,\n",
    "                                    query.message.message_id,\n",
    "                                    caption = msg,\n",
    "                                    reply_markup=get_keyboard(keyboard),\n",
    "                                    parse_mode = 'HTML')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab9d2645-5b53-4854-a2ec-31e697394565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_dish pushed\n",
    "@dp.callback_query_handler(add_dish_cb.filter(action=['add_dish']))\n",
    "async def add_dish(query: types.CallbackQuery, callback_data: typing.Dict[str, str]):\n",
    "    logger.debug({'func':'add_dish','id_key':'user_id','id_value':query['from']['id'],'msg':'add_dish'})\n",
    "    \n",
    "    await add_remove(query,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dabd7641-30e2-4897-b499-0b83604f8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_dish pushed\n",
    "@dp.callback_query_handler(remove_cb.filter(action=['remove']))\n",
    "async def remove_dish(query: types.CallbackQuery, callback_data: typing.Dict[str, str]):\n",
    "    logger.debug({'func':'remove_dish','id_key':'user_id','id_value':query['from']['id'],'msg':'remove_dish'})\n",
    "    \n",
    "    await add_remove(query,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22f1ab84-9b82-4e2d-9674-ba3ca836e8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/types/mixins.py:40: DeprecationWarning: destination parameter is deprecated, please use destination_dir or destination_file.\n",
      "  warn_deprecated(\n",
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after search\n",
      "downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/types/mixins.py:40: DeprecationWarning: destination parameter is deprecated, please use destination_dir or destination_file.\n",
      "  warn_deprecated(\n",
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after search\n",
      "downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/types/mixins.py:40: DeprecationWarning: destination parameter is deprecated, please use destination_dir or destination_file.\n",
      "  warn_deprecated(\n",
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after search\n",
      "downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/types/mixins.py:40: DeprecationWarning: destination parameter is deprecated, please use destination_dir or destination_file.\n",
      "  warn_deprecated(\n",
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after search\n",
      "downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-226' coro=<Dispatcher._process_polling_updates() done, defined at /home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py:407> exception=TypeError(\"'<' not supported between instances of 'NoneType' and 'int'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/asyncio/tasks.py\", line 258, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py\", line 415, in _process_polling_updates\n",
      "    for responses in itertools.chain.from_iterable(await self.process_updates(updates, fast)):\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py\", line 235, in process_updates\n",
      "    return await asyncio.gather(*tasks)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/asyncio/tasks.py\", line 328, in __wakeup\n",
      "    future.result()\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/handler.py\", line 116, in notify\n",
      "    response = await handler_obj.handler(*args, **partial_data)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py\", line 283, in process_update\n",
      "    return await self.callback_query_handlers.notify(update.callback_query)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/handler.py\", line 116, in notify\n",
      "    response = await handler_obj.handler(*args, **partial_data)\n",
      "  File \"/tmp/ipykernel_1933593/1397637517.py\", line 6, in remove_dish\n",
      "    await add_remove(query,False)\n",
      "  File \"/tmp/ipykernel_1933593/3076530629.py\", line 19, in add_remove\n",
      "    if cals_score < 70:\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'int'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-232' coro=<Dispatcher._process_polling_updates() done, defined at /home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py:407> exception=TypeError(\"'<' not supported between instances of 'NoneType' and 'int'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/asyncio/tasks.py\", line 258, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py\", line 415, in _process_polling_updates\n",
      "    for responses in itertools.chain.from_iterable(await self.process_updates(updates, fast)):\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py\", line 235, in process_updates\n",
      "    return await asyncio.gather(*tasks)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/asyncio/tasks.py\", line 328, in __wakeup\n",
      "    future.result()\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/handler.py\", line 116, in notify\n",
      "    response = await handler_obj.handler(*args, **partial_data)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py\", line 283, in process_update\n",
      "    return await self.callback_query_handlers.notify(update.callback_query)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/handler.py\", line 116, in notify\n",
      "    response = await handler_obj.handler(*args, **partial_data)\n",
      "  File \"/tmp/ipykernel_1933593/1397637517.py\", line 6, in remove_dish\n",
      "    await add_remove(query,False)\n",
      "  File \"/tmp/ipykernel_1933593/3076530629.py\", line 19, in add_remove\n",
      "    if cals_score < 70:\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'int'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-295' coro=<Dispatcher._process_polling_updates() done, defined at /home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py:407> exception=MessageNotModified('Message is not modified: specified new message content and reply markup are exactly the same as a current content and reply markup of the message')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/asyncio/tasks.py\", line 258, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py\", line 415, in _process_polling_updates\n",
      "    for responses in itertools.chain.from_iterable(await self.process_updates(updates, fast)):\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py\", line 235, in process_updates\n",
      "    return await asyncio.gather(*tasks)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/asyncio/tasks.py\", line 328, in __wakeup\n",
      "    future.result()\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/handler.py\", line 116, in notify\n",
      "    response = await handler_obj.handler(*args, **partial_data)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/dispatcher.py\", line 283, in process_update\n",
      "    return await self.callback_query_handlers.notify(update.callback_query)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/dispatcher/handler.py\", line 116, in notify\n",
      "    response = await handler_obj.handler(*args, **partial_data)\n",
      "  File \"/tmp/ipykernel_1933593/3226037485.py\", line 6, in add_dish\n",
      "    await add_remove(query,True)\n",
      "  File \"/tmp/ipykernel_1933593/3076530629.py\", line 42, in add_remove\n",
      "    await bot.edit_message_caption(query.from_user.id,\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/bot/bot.py\", line 2824, in edit_message_caption\n",
      "    result = await self.request(api.Methods.EDIT_MESSAGE_CAPTION, payload)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/bot/base.py\", line 236, in request\n",
      "    return await api.make_request(await self.get_session(), self.server, self.__token, method, data, files,\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/bot/api.py\", line 140, in make_request\n",
      "    return check_result(method, response.content_type, response.status, await response.text())\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/bot/api.py\", line 115, in check_result\n",
      "    exceptions.BadRequest.detect(description)\n",
      "  File \"/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/utils/exceptions.py\", line 140, in detect\n",
      "    raise err(cls.text or description)\n",
      "aiogram.utils.exceptions.MessageNotModified: Message is not modified: specified new message content and reply markup are exactly the same as a current content and reply markup of the message\n",
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/aiogram/types/mixins.py:40: DeprecationWarning: destination parameter is deprecated, please use destination_dir or destination_file.\n",
      "  warn_deprecated(\n",
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/dima/anaconda3/envs/f1/lib/python3.9/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after search\n",
      "downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': executor.start_polling(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a3c0e-b9b4-4f5c-a821-f56bf66e34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #thumbs up pushed\n",
    "# @dp.callback_query_handler(add_dish_cb.filter(action=[':thumbs_up:']))\n",
    "# async def add_dish(query: types.CallbackQuery, callback_data: typing.Dict[str, str]):\n",
    "#     logger.debug({'func':'thumbs up','id_key':'message_id','id_value':query.message.message_id,'msg':'thumbs up'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "11d09d9e-05fc-4fec-bbd8-fb72f362cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #thumbs down pushed\n",
    "# @dp.callback_query_handler(add_dish_cb.filter(action=[':thumbs_down:']))\n",
    "# async def add_dish(query: types.CallbackQuery, callback_data: typing.Dict[str, str]):\n",
    "#     logger.debug({'func':'thumbs down','id_key':'message_id','id_value':query.message.message_id,'msg':'thumbs down'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1",
   "language": "python",
   "name": "f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
