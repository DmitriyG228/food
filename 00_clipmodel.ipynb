{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp clipmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device success 0\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel, CLIPTokenizer\n",
    "from PIL import Image, ImageOps\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from wrapt import synchronized\n",
    "\n",
    "def img_resize(image, size):\n",
    "    return ImageOps.fit(image, (size,size), Image.LANCZOS)\n",
    "\n",
    "def imgs_resize(images, size):\n",
    "    with Pool(32) as p:\n",
    "        return p.map(partial(img_resize, size=size), images)\n",
    "\n",
    "#########################################################################################################################\n",
    "# en model\n",
    "\n",
    "en_model_name = 'openai/clip-vit-large-patch14' \n",
    "tokenizer = CLIPTokenizer.from_pretrained(en_model_name)\n",
    "en_processor = CLIPProcessor.from_pretrained(en_model_name)\n",
    "\n",
    "\n",
    "for device in range(0,3):\n",
    "    try:\n",
    "        model = CLIPModel.from_pretrained(en_model_name).cuda(device)\n",
    "        print(f'device success {device}')\n",
    "        break\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "en_size = model.config.vision_config.image_size\n",
    "en_dim = model.config.projection_dim\n",
    "\n",
    "def dict_to_device(d,device):\n",
    "    for key, value in d.items():\n",
    "        d[key] = d[key].to(device)\n",
    "    return d\n",
    "\n",
    "def norm(v): \n",
    "    return v/torch.linalg.norm(v, dim=-1, keepdim=True)\n",
    "\n",
    "def detach_norm(v):\n",
    "    v = v.cpu().detach().squeeze()\n",
    "    return norm(v)\n",
    "\n",
    "@synchronized\n",
    "def text2clip_en(text):\n",
    "    inputs = tokenizer([text],  padding=True, return_tensors=\"pt\")\n",
    "    inputs = dict_to_device(inputs,device)\n",
    "    text_features = model.get_text_features(**inputs)\n",
    "    return detach_norm(text_features)\n",
    "\n",
    "@synchronized\n",
    "def images2clip_en(images): \n",
    "    images = imgs_resize(images, size=en_size)\n",
    "    inputs = en_processor(images=images, return_tensors=\"pt\")\n",
    "    inputs = dict_to_device(inputs,device)\n",
    "    image_features = model.get_image_features(**inputs)\n",
    "    return detach_norm(image_features) \n",
    "\n",
    "#########################################################################################################################\n",
    "# mix model\n",
    "\n",
    "images2clip = images2clip_en\n",
    "\n",
    "def image2clip(image): return images2clip([image])\n",
    "\n",
    "text2clip = text2clip_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_clipmodel.ipynb.\n",
      "Converted 00_custom_pandas.ipynb.\n",
      "Converted 00_onehot.ipynb.\n",
      "Converted 00_paths.ipynb.\n",
      "Converted 00_progress_check.ipynb.\n",
      "Converted 00_psql.ipynb.\n",
      "Converted 00_qdrant.ipynb.\n",
      "Converted 00_quantization.ipynb.\n",
      "Converted 00_search.ipynb.\n",
      "Converted 00_tools.ipynb.\n",
      "Converted 0_template.ipynb.\n",
      "Converted meta_prep.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6365d061e81b8c0bb3064d6704cf11d6e40dd3bb5a1988259337fb2df5fb9180"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('re')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
