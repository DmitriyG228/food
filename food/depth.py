# AUTOGENERATED! DO NOT EDIT! File to edit: ../00_nbs/depth.ipynb.

# %% auto 0
__all__ = ['feature_extractor', 'model', 'get_depth']

# %% ../00_nbs/depth.ipynb 1
from transformers import GLPNFeatureExtractor, GLPNForDepthEstimation
import torch
import numpy as np
from PIL import Image
import requests

feature_extractor = GLPNFeatureExtractor.from_pretrained("vinvino02/glpn-nyu")
model = GLPNForDepthEstimation.from_pretrained("vinvino02/glpn-nyu")

# %% ../00_nbs/depth.ipynb 2
def get_depth(image,mean_height=3.,cut_min_q=0.3):
    pixel_values = feature_extractor(image, return_tensors="pt").pixel_values


    with torch.no_grad():
        outputs = model(pixel_values)
        predicted_depth = outputs.predicted_depth

    # interpolate to original size
    prediction = torch.nn.functional.interpolate(
                        predicted_depth.unsqueeze(1),
                        size=pixel_values.shape[-2:],
                        mode="bicubic",
                        align_corners=False,
                 )
    prediction = -prediction.squeeze().cpu().numpy()
    prediction = prediction-prediction.min()
    min_ = np.quantile(prediction, cut_min_q)
    prediction = np.where(prediction<min_,min_,prediction)
    prediction = prediction-min_
    return prediction*mean_height/prediction.mean()
